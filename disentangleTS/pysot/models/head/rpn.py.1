# Copyright (c) SenseTime. All Rights Reserved.

from __future__ import absolute_import
from __future__ import division
from __future__ import print_function
from __future__ import unicode_literals

import torch
import torch.nn as nn
import torch.nn.functional as F
from IPython import embed
from .reconstruction import Decoder
#from pysot.core.xcorr import xcorr_fast, xcorr_depthwise
#from pysot.models.init_weight import init_weights

class RPN(nn.Module):
    def __init__(self):
        super(RPN, self).__init__()

    def forward(self, z_f, x_f):
        raise NotImplementedError
class DepthwiseXCorr(nn.Module):
    def __init__(self, in_channels, hidden, out_channels, kernel_size=3, hidden_kernel_size=5):
        super(DepthwiseXCorr, self).__init__()
        #self.split_channel=hidden//4
        self.conv_kernel = nn.Sequential(
                nn.Conv2d(in_channels, hidden, kernel_size=kernel_size, bias=False),
                nn.BatchNorm2d(hidden),
                nn.ReLU(inplace=True),
                )
        self.conv_search = nn.Sequential(
                nn.Conv2d(in_channels, hidden, kernel_size=kernel_size, bias=False),
                nn.BatchNorm2d(hidden),
                nn.ReLU(inplace=True),
                )

        self.split_fg = nn.Sequential(
                nn.Conv2d(hidden, hidden//2, kernel_size=1, bias=False),
                nn.BatchNorm2d(hidden//2),
                nn.ReLU(inplace=True),
                )
        self.split_bg = nn.Sequential(
                nn.Conv2d(hidden, hidden//2, kernel_size=1, bias=False),
                nn.BatchNorm2d(hidden//2),
                nn.ReLU(inplace=True),
                )
        self.head = nn.Sequential(
                nn.Conv2d(hidden//2, hidden//4, kernel_size=1, bias=False),
                nn.BatchNorm2d(hidden//4),
                nn.ReLU(inplace=True),
                nn.Conv2d(hidden//4, out_channels, kernel_size=1)
                )
        self.softmax=torch.nn.Softmax(dim=1)
        self.fgreconstruct = Decoder(5, 2, 128, 3, res_norm='in', activ='relu', pad_type='zero')
        self.bgreconstruct = Decoder(5, 2, 128, 3, res_norm='in', activ='relu', pad_type='zero')
        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                nn.init.kaiming_normal_(m.weight.data,
                                        mode='fan_out',
                                        nonlinearity='relu')
            elif isinstance(m, nn.BatchNorm2d):
                m.weight.data.fill_(1)
                m.bias.data.zero_()

    def forward(self, kernel, search):
        kernel = self.conv_kernel(kernel)
        search = self.conv_search(search)
        #split z_f and x_f to four kinds of feature which are the c_f,s_f,c_b,s_b, for content and style
        #foreground and background
        #weight_kernel_fb = self.softmax(self.split_w_fb(kernel))
        kernel_fg = self.split_fg(kernel) #128*4*4
        kernel_bg = self.split_bg(kernel) #128*4*4
        fg = self.fgreconstruct(kernel_fg) #127,127,3
        bg = self.bgreconstruct(kernel_bg) #255,255,3
        embed()
        #weight_search_fb = self.softmax(self.split_w_fb(search))
        search_fg = self.split_fg(search)
        search_bg = self.split_bg(search)

        ####fb-loss
        k_k_fb = torch.mean(torch.sum(kernel_fg * kernel_bg,dim=1))
        s_s_fb = torch.mean(torch.sum(search_fg * search_bg,dim=1))
        k_s = k_k_fb+s_s_fb

        k_s_ff = xcorr_depthwise(kernel_fg,search_fg)
        k_s_fb = xcorr_depthwise(kernel_fg,search_bg)
        k_s_bf = xcorr_depthwise(kernel_bg,search_fg)
        k_s_bb = xcorr_depthwise(kernel_bg,search_bg)
        #feature = 1*k_s_ff+(-0.1)*(k_s_fb+k_s_bf)+0.4*k_s_bb
        feature = 0.4*k_s_ff + k_s_fb + k_s_bf+ 0.4*k_s_bb
        out = self.head(feature)
        features={}
        features['k_s'] = k_s
        features['kernel_fg'] = kernel_fg
        features['kernel_bg'] = kernel_bg
        features['search_fg'] = search_fg
        features['search_bg'] = search_bg
        features['fg'] = fg
        features['bg'] = bg
        return out,features
def xcorr_depthwise( kernel,x):
    """depthwise cross correlation
    """
    batch = kernel.size(0)
    channel = kernel.size(1)
    x = x.view(1, batch*channel, x.size(2), x.size(3))
    kernel = kernel.view(batch*channel, 1, kernel.size(2), kernel.size(3))
    out = F.conv2d(x, kernel, groups=batch*channel)
    out = out.view(batch, channel, out.size(2), out.size(3))
    return out

class DepthwiseRPN(RPN):
    def __init__(self, anchor_num=5, in_channels=256, out_channels=256):
        super(DepthwiseRPN, self).__init__()
        self.cls = DepthwiseXCorr(in_channels, out_channels, 2 * anchor_num)
        self.loc = DepthwiseXCorr(in_channels, out_channels, 4 * anchor_num)

    def forward(self, z_f, x_f):

        cls, cls_features = self.cls(z_f, x_f)
        loc, loc_features = self.loc(z_f, x_f)
        k_s_all = cls_features['k_s']+loc_features['k_s']
        return cls, loc